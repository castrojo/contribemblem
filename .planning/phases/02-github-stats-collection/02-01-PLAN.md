---
phase: 02-github-stats-collection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/fetch-stats.sh
  - scripts/process-stats.sh
  - .github/workflows/update-emblem.yml
  - data/.gitkeep
autonomous: true

must_haves:
  truths:
    - "Workflow fetches 5 GitHub metrics (commits, PRs, issues, reviews, stars) for current calendar year"
    - "API responses are cached for 24 hours to prevent redundant API calls"
    - "Rate limit remaining quota is logged on every API call"
    - "Stats correctly reflect current year even on January 1 (UTC boundary handling)"
    - "Cache hit on second run within same day (no redundant API fetch)"
  artifacts:
    - path: "scripts/fetch-stats.sh"
      provides: "GraphQL query execution with UTC date boundaries and rate limit monitoring"
      min_lines: 40
    - path: "scripts/process-stats.sh"
      provides: "Transforms GraphQL response into standardized stats.json format"
      min_lines: 20
    - path: ".github/workflows/update-emblem.yml"
      provides: "Cache integration with date-based key and conditional fetch"
      contains: "actions/cache@v4"
    - path: "data/stats.json"
      provides: "Cached stats output with 5 metrics + metadata"
      contains: '"year"'
  key_links:
    - from: ".github/workflows/update-emblem.yml"
      to: "scripts/fetch-stats.sh"
      via: "conditional execution on cache miss"
      pattern: "if:.*cache-hit.*!= 'true'"
    - from: "scripts/fetch-stats.sh"
      to: "scripts/process-stats.sh"
      via: "pipe GraphQL response to jq processor"
      pattern: "\\|.*process-stats\\.sh"
    - from: "scripts/fetch-stats.sh"
      to: "https://api.github.com/graphql"
      via: "curl with GITHUB_TOKEN authorization"
      pattern: "curl.*Authorization.*GITHUB_TOKEN"
---

<objective>
Create GitHub stats collection infrastructure that fetches current year contribution data via GraphQL API with 24-hour caching and rate limit protection.

Purpose: Enable the action to gather contribution metrics (commits, PRs, issues, reviews, stars) efficiently without hitting GitHub rate limits, providing the data foundation for Phase 4's Power Level calculation.

Output: 
- Bash scripts for GraphQL query execution and response processing
- GitHub Actions workflow integration with cache action
- Standardized stats.json file with current year metrics
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-github-stats-collection/02-RESEARCH.md
@.planning/phases/01-github-actions-foundation/01-01-SUMMARY.md
@.github/workflows/update-emblem.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GraphQL stats fetching scripts with UTC boundaries and rate limit monitoring</name>
  <files>
    scripts/fetch-stats.sh
    scripts/process-stats.sh
    data/.gitkeep
  </files>
  <action>
Create `scripts/fetch-stats.sh` that executes GraphQL query for current year contributions:

**Key implementation details:**
- Calculate current year boundaries in UTC using `date -u +"%Y"` to avoid January 1 timezone edge cases (see RESEARCH.md Pitfall 1)
- Use ISO 8601 full-day boundaries: `YYYY-01-01T00:00:00Z` to `YYYY-12-31T23:59:59Z` (matches GitHub's contribution counting logic)
- Build GraphQL query with `contributionsCollection(from: $from, to: $to)` for date filtering
- Fetch 5 metrics: totalCommitContributions, totalPullRequestContributions, totalIssueContributions, totalPullRequestReviewContributions
- For stars: query `repositories(ownerAffiliations: OWNER, first: 100)` and sum stargazerCount (see RESEARCH.md Pattern 1)
- Execute with `curl -H "Authorization: bearer $GITHUB_TOKEN"` against `https://api.github.com/graphql`
- Extract and log `x-ratelimit-remaining` header (case-insensitive grep, strip carriage returns)
- Extract response body (JSON after blank line separating headers)
- Pipe response to `process-stats.sh` for transformation

Create `scripts/process-stats.sh` that transforms GraphQL response into standardized format:

**Output format (data/stats.json):**
```json
{
  "year": 2026,
  "updated_at": "2026-01-27T22:30:00Z",
  "commits": 150,
  "pull_requests": 25,
  "issues": 10,
  "reviews": 30,
  "stars_received": 42
}
```

Use `jq` for JSON processing (built into GitHub runners):
- Extract nested fields from `.data.user.contributionsCollection.*`
- Sum star counts from `.data.user.repositories.nodes[].stargazerCount` using `[...] | add // 0` for empty fallback
- Add current timestamp with `now | strftime("%Y-%m-%dT%H:%M:%SZ")`

**Error handling:**
- Set `set -euo pipefail` in both scripts (fail fast on errors)
- Don't fail workflow if rate limit low - just log warning (non-blocking monitoring per RESEARCH.md Pattern 4)

**Script permissions:**
Make scripts executable: `chmod +x scripts/fetch-stats.sh scripts/process-stats.sh`

Create `data/.gitkeep` to ensure data directory exists (stats.json generated at runtime, not committed).

**Reference:** Use code examples from 02-RESEARCH.md sections "Fetch Stats with GraphQL" and "Process GraphQL Response into stats.json"
  </action>
  <verify>
Run scripts manually to test:
```bash
export GITHUB_TOKEN="${{ secrets.GITHUB_TOKEN }}"
export GITHUB_ACTOR="testuser"
./scripts/fetch-stats.sh > data/stats.json
cat data/stats.json  # Should show JSON with 5 metrics + year + updated_at
grep -E '"year"|"commits"|"pull_requests"' data/stats.json  # Verify structure
```

Check rate limit logging appears in stdout.
  </verify>
  <done>
- scripts/fetch-stats.sh exists and is executable
- scripts/process-stats.sh exists and is executable  
- scripts/fetch-stats.sh outputs valid JSON with 7 fields (year, updated_at, 5 metrics)
- Rate limit remaining is logged to stdout on execution
- Date boundaries use UTC timezone (no hardcoded offsets)
- data/.gitkeep created
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate caching into workflow with date-based key and conditional fetch</name>
  <files>
    .github/workflows/update-emblem.yml
  </files>
  <action>
Update `.github/workflows/update-emblem.yml` to integrate stats caching and conditional fetching.

**Add after "Configure git" step:**

1. **Get current date (UTC) for cache key:**
```yaml
- name: Get current date (UTC)
  id: get-date
  run: echo "date=$(date -u +%Y%m%d)" >> $GITHUB_OUTPUT
```

2. **Cache GitHub Stats with date-based key:**
```yaml
- name: Cache GitHub Stats
  id: cache-stats
  uses: actions/cache@v4
  with:
    path: data/stats.json
    key: github-stats-${{ steps.get-date.outputs.date }}
    restore-keys: |
      github-stats-
```

**Rationale for date-based key:** Cache key includes `YYYYMMDD` format, ensuring cache rotates daily (24-hour effective TTL). `restore-keys` allows fallback to previous day's cache if current day cache doesn't exist yet (see RESEARCH.md Pattern 2).

3. **Create data directory:**
```yaml
- name: Create data directory
  run: mkdir -p data
```

4. **Fetch stats only if cache miss:**
```yaml
- name: Fetch GitHub Stats
  if: steps.cache-stats.outputs.cache-hit != 'true'
  run: |
    chmod +x scripts/fetch-stats.sh scripts/process-stats.sh
    ./scripts/fetch-stats.sh > data/stats.json
  env:
    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    GITHUB_ACTOR: ${{ github.actor }}
```

5. **Log cache status:**
```yaml
- name: Log stats status
  run: |
    if [ "${{ steps.cache-stats.outputs.cache-hit }}" == "true" ]; then
      echo "✓ Using cached stats from previous run (within 24 hours)"
    else
      echo "✓ Fetched fresh stats from GitHub API"
    fi
    echo "Stats for year: $(jq -r '.year' data/stats.json)"
    echo "Last updated: $(jq -r '.updated_at' data/stats.json)"
    echo "Power Level: $(jq '[.commits, .pull_requests, .issues, .reviews, .stars_received] | add' data/stats.json)"
```

**Replace placeholder steps:**
Remove "Generate emblem (placeholder)" and "Create placeholder file" steps - these are replaced by the stats fetching logic above.

**Preserve existing logic:**
Keep "Check for changes" and "Commit and push if changed" steps as-is (Phase 5 will update commit logic to handle stats.json + emblem image).

**Important:** Do NOT add `data/stats.json` to git yet - caching means it's regenerated on each run. Phase 5 will handle committing generated artifacts.
  </action>
  <verify>
Test workflow integration:
```bash
# Trigger workflow manually
gh workflow run update-emblem.yml

# Wait for completion, then check logs
gh run view --log | grep -A5 "Cache GitHub Stats"
gh run view --log | grep "cache-hit"
gh run view --log | grep "Rate limit remaining"
gh run view --log | grep "Power Level"

# Verify cache was created
gh run view --log | grep "Cache saved successfully"
```

On second run within same day, verify cache hit:
```bash
gh workflow run update-emblem.yml
# Wait ~30 seconds
gh run view --log | grep "Using cached stats from previous run"
```
  </verify>
  <done>
- Workflow includes actions/cache@v4 step with date-based cache key
- Cache path points to data/stats.json
- Fetch stats step runs only when cache-hit != 'true'
- Date boundaries calculated in UTC
- GITHUB_TOKEN and GITHUB_ACTOR passed as environment variables
- Log output shows cache status (hit/miss) and Power Level calculation
- Placeholder emblem generation steps removed
  </done>
</task>

</tasks>

<verification>

**Phase 2 Success Criteria:**

1. **STATS-01** ✓ Action fetches GitHub contribution stats via GraphQL API
   - Verify: `gh run view --log | grep "api.github.com/graphql"`

2. **STATS-02** ✓ Stats filtered to current calendar year only (Jan 1 - Dec 31)
   - Verify: Check data/stats.json has current year: `jq -r '.year' data/stats.json`
   - Verify: GraphQL query uses full-day UTC boundaries (01-01T00:00:00Z to 12-31T23:59:59Z)

3. **STATS-03** ✓ API responses cached with 24hr expiry
   - Verify: Second workflow run within same day shows "Using cached stats" message
   - Verify: Cache key includes date: `github-stats-YYYYMMDD`

4. **STATS-04** ✓ Rate limit headers monitored and logged
   - Verify: Workflow logs contain "Rate limit remaining: [number]"

5. **STATS-05** ✓ Stats include: commits, PRs, issues, code reviews, stars received
   - Verify: `jq 'keys' data/stats.json` shows all 5 metrics plus year and updated_at

**Edge case tests:**
- Run workflow on January 1 (simulate with `date -u` override) - stats.json should show new year
- Run twice within same day - second run uses cache (no API call)
- Check rate limit doesn't block workflow (just logs warning if low)

</verification>

<success_criteria>

Phase 2 complete when:
- [ ] scripts/fetch-stats.sh executes GraphQL query with UTC date boundaries
- [ ] scripts/process-stats.sh transforms response into stats.json with 7 fields
- [ ] Workflow uses actions/cache@v4 with date-based key (daily rotation)
- [ ] Conditional fetch only runs on cache miss
- [ ] Rate limit remaining is logged on every API call
- [ ] data/stats.json contains current year stats with all 5 metrics
- [ ] Cache hit on second run within 24 hours (no redundant API fetch)
- [ ] Power Level (sum of 5 metrics) is logged to workflow output

</success_criteria>

<output>
After completion, create `.planning/phases/02-github-stats-collection/02-01-SUMMARY.md`

Summary should document:
- Final cache key format and TTL strategy
- GraphQL query structure and date boundary handling
- Rate limit consumption per run (from logs)
- Any deviations from plan (e.g., jq filter adjustments)
- Power Level sample output from test run
</output>
